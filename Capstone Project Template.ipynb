{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      int64\n",
      "cicid         float64\n",
      "i94yr         float64\n",
      "i94mon        float64\n",
      "i94cit        float64\n",
      "i94res        float64\n",
      "i94port        object\n",
      "arrdate       float64\n",
      "i94mode       float64\n",
      "i94addr        object\n",
      "depdate       float64\n",
      "i94bir        float64\n",
      "i94visa       float64\n",
      "count         float64\n",
      "dtadfile        int64\n",
      "visapost       object\n",
      "occup          object\n",
      "entdepa        object\n",
      "entdepd        object\n",
      "entdepu       float64\n",
      "matflag        object\n",
      "biryear       float64\n",
      "dtaddto        object\n",
      "gender         object\n",
      "insnum        float64\n",
      "airline        object\n",
      "admnum        float64\n",
      "fltno          object\n",
      "visatype       object\n",
      "dtype: object\n",
      "dt                                object\n",
      "AverageTemperature               float64\n",
      "AverageTemperatureUncertainty    float64\n",
      "City                              object\n",
      "Country                           object\n",
      "Latitude                          object\n",
      "Longitude                         object\n",
      "dtype: object\n",
      "City                       object\n",
      "State                      object\n",
      "Median Age                float64\n",
      "Male Population           float64\n",
      "Female Population         float64\n",
      "Total Population            int64\n",
      "Number of Veterans        float64\n",
      "Foreign-born              float64\n",
      "Average Household Size    float64\n",
      "State Code                 object\n",
      "Race                       object\n",
      "Count                       int64\n",
      "dtype: object\n",
      "ident            object\n",
      "type             object\n",
      "name             object\n",
      "elevation_ft    float64\n",
      "continent        object\n",
      "iso_country      object\n",
      "iso_region       object\n",
      "municipality     object\n",
      "gps_code         object\n",
      "iata_code        object\n",
      "local_code       object\n",
      "coordinates      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read in the data here and print columns and types\n",
    "# immigration_data small\n",
    "df_immigration = pd.read_csv('data/immigration_data_sample.csv')\n",
    "print( df_immigration.dtypes)\n",
    "\n",
    "# temperature data\n",
    "df_temperature = pd.read_csv('data/Global_temperature/GlobalLandTemperaturesByCity.csv')\n",
    "print(df_temperature.dtypes)\n",
    "\n",
    "# demographics data\n",
    "df_dem = pd.read_csv('data/Us_city_demographics/us-cities-demographics.csv', delimiter = ';')\n",
    "print(df_dem.dtypes)\n",
    "\n",
    "# airport data\n",
    "df_air = pd.read_csv('data/airport-codes_csv.csv')\n",
    "print(df_air.dtypes)\n",
    "\n",
    "# immigration data big file\n",
    "df_imm_par = pd.read_parquet(\"data/sas_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(1960, 1, 1)\n",
    "\n",
    "# Performing cleaning tasks here\n",
    "# demographics \n",
    "# remove race table aggregation over city will be conducted with in redshift\n",
    "df_dem_clean = df_dem.drop(['Race','Count'], axis=1).drop_duplicates()\n",
    "df_dem_clean.sort_values('City')\n",
    "\n",
    "# rename columns with spaces\n",
    "df_dem_clean = df_dem_clean.rename(columns={\"Median Age\":\"Median_Age\", \"Male_Population\":\"Male_Population\",\n",
    "                       \"Female Population\":\"Female_Population\",\n",
    "                       \"Total Population\": \"Total_Population\",\n",
    "                       \"Number of Veterans\": \"Number_of_Veterans\",\n",
    "                       \"Average Household Size\":\"Average_Household_Size\",\n",
    "                       \"State Code\":\"State_Code\",\n",
    "                       \"Foreign-born\": \"Foreign_born\"})\n",
    "\n",
    "# back to csv write\n",
    "df_dem_clean.to_csv('Data_clean/demographics_data.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cicid        0.000000\n",
      "i94yr        0.000000\n",
      "i94mon       0.000000\n",
      "i94cit       0.000000\n",
      "i94res       0.000000\n",
      "i94port      0.000000\n",
      "arrdate      0.000000\n",
      "i94mode      0.004241\n",
      "i94addr      3.357000\n",
      "depdate      3.862618\n",
      "i94bir       0.000808\n",
      "i94visa      0.000000\n",
      "count        0.000000\n",
      "dtadfile     0.000050\n",
      "visapost    60.339714\n",
      "occup       99.723006\n",
      "entdepa      0.004191\n",
      "entdepd      3.862315\n",
      "entdepu     99.986620\n",
      "matflag      3.862315\n",
      "biryear      0.000808\n",
      "dtaddto      0.006463\n",
      "gender      14.553598\n",
      "insnum      99.965666\n",
      "airline      0.037060\n",
      "admnum       0.000000\n",
      "fltno        0.037666\n",
      "visatype     0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# immigration\n",
    "# remove columns with high nan percentage\n",
    "print(df_imm_par.isnull().sum() * 100 / len(df_imm_par))\n",
    "df_immigration_clean = df_imm_par.drop(['visapost', 'occup', 'entdepu', 'insnum'], axis = 1)\n",
    "\n",
    "# make sense of arrdate en depdate\n",
    "df_immigration_clean['arrdate'] = pd.to_timedelta(df_immigration_clean['arrdate'], unit = 'day') + start\n",
    "df_immigration_clean['arrdate'] = pd.to_datetime(df_immigration_clean['arrdate'], unit='day', origin = 'unix')\n",
    "df_immigration_clean['depdate'] = pd.to_timedelta(df_immigration_clean['depdate'], unit = 'day') + start\n",
    "\n",
    "\n",
    "# write back to parquet\n",
    "df_immigration_clean.to_parquet('Data_clean/i94_unpar/unpar.snappy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599207</th>\n",
       "      <td>5</td>\n",
       "      <td>11.464</td>\n",
       "      <td>0.236</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599208</th>\n",
       "      <td>6</td>\n",
       "      <td>15.043</td>\n",
       "      <td>0.261</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599209</th>\n",
       "      <td>7</td>\n",
       "      <td>18.775</td>\n",
       "      <td>0.193</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599210</th>\n",
       "      <td>8</td>\n",
       "      <td>18.025</td>\n",
       "      <td>0.298</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8599211</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zwolle</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>52.24N</td>\n",
       "      <td>5.26E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8599212 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dt  AverageTemperature  AverageTemperatureUncertainty    City  \\\n",
       "0        11               6.068                          1.737   Århus   \n",
       "1        12                 NaN                            NaN   Århus   \n",
       "2         1                 NaN                            NaN   Århus   \n",
       "3         2                 NaN                            NaN   Århus   \n",
       "4         3                 NaN                            NaN   Århus   \n",
       "...      ..                 ...                            ...     ...   \n",
       "8599207   5              11.464                          0.236  Zwolle   \n",
       "8599208   6              15.043                          0.261  Zwolle   \n",
       "8599209   7              18.775                          0.193  Zwolle   \n",
       "8599210   8              18.025                          0.298  Zwolle   \n",
       "8599211   9                 NaN                            NaN  Zwolle   \n",
       "\n",
       "             Country Latitude Longitude  \n",
       "0            Denmark   57.05N    10.33E  \n",
       "1            Denmark   57.05N    10.33E  \n",
       "2            Denmark   57.05N    10.33E  \n",
       "3            Denmark   57.05N    10.33E  \n",
       "4            Denmark   57.05N    10.33E  \n",
       "...              ...      ...       ...  \n",
       "8599207  Netherlands   52.24N     5.26E  \n",
       "8599208  Netherlands   52.24N     5.26E  \n",
       "8599209  Netherlands   52.24N     5.26E  \n",
       "8599210  Netherlands   52.24N     5.26E  \n",
       "8599211  Netherlands   52.24N     5.26E  \n",
       "\n",
       "[8599212 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temperature data\n",
    "def mean_str(col):\n",
    "    if is_numeric_dtype(col):\n",
    "        return col.mean()\n",
    "    else:\n",
    "        return col.unique() if col.nunique() == 1 else np.NaN\n",
    "    \n",
    "df_temp_clean = df_temperature\n",
    "\n",
    "# change dt to datetime\n",
    "df_temp_clean['dt']=pd.to_datetime(df_temp_clean['dt'])\n",
    "df_temp_clean['dt']=pd.DatetimeIndex(df_temp_clean['dt']).month\n",
    "\n",
    "# group by city and month\n",
    "df_temp_clean= df_temp_clean.groupby(['dt', 'City']).agg(mean_str)\n",
    "\n",
    "# write back to csv\n",
    "df_temp_clean.to_csv('Data_clean/temperature_data.csv')\n",
    "df_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airport data\n",
    "# where iata code exists\n",
    "df_air_clean = df_air[df_air['iata_code'].notna()].drop(['gps_code', 'local_code'], axis = 1)\n",
    "\n",
    "# and country is us\n",
    "df_air_clean = df_air_clean[df_air_clean['iso_country']=='US']\n",
    "\n",
    "# remove columns not needed\n",
    "df_air_clean = df_air_clean.drop(['continent','iso_country', 'ident'], axis = 1)\n",
    "\n",
    "# for region only keep the state code\n",
    "df_air_clean[\"iso_region\"] = df_air_clean[\"iso_region\"].str.replace(\"US-\", \"\")\n",
    "\n",
    "# write back to csv\n",
    "df_air_clean.to_csv('Data_clean/airport_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here\n",
    "# see airflow dags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
